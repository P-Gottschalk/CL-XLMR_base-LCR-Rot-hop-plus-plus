{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["###**Notebook Setup**"],"metadata":{"id":"A6IwkaSjh1Ul"}},{"cell_type":"markdown","source":["**Mount Prep**"],"metadata":{"id":"IEAxUJ-S2dJB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZlNusdLTV0v"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"]},{"cell_type":"markdown","metadata":{"id":"vkx1Y9Qj5G_1"},"source":["**Package Installation:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wZfrg344lsI"},"outputs":[],"source":["! pip install matplotlib\n","! pip install torch\n","! pip install transformers\n","! pip install datasets\n","! pip install rdflib\n","! pip install tqdm\n","! pip install requests\n","! pip install hyperopt\n","! pip install scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"nu6jBbPL2q4F"},"source":["**GitHub Cloning:** 90-day access token is used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-qbm4XreAUf"},"outputs":[],"source":["! rm -r CL-XLMR_base-LCR-Rot-hop-plus-plus #Remove GitHub whilst in session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9Ovr3oPvWD7"},"outputs":[],"source":["!git clone https://github.com/SmartStevie02/CL-XLMR_base-LCR-Rot-hop-plus-plus.git"]},{"cell_type":"markdown","source":["### **XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset."],"metadata":{"id":"Z6lXkq_w28id"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using English language training data."],"metadata":{"id":"wUulWFqcAuaV"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"mBERT\""],"metadata":{"id":"J9LtrDDpsK9Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"xlm-roberta-base\""],"metadata":{"id":"hyoQsG3hsK9Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"xlm-roberta-large\""],"metadata":{"id":"q8VZWQ_usK9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using English language training data."],"metadata":{"id":"oSK97jQjBw1q"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05"],"metadata":{"id":"MzdHkxt0B88x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.05 --dropout 0.5 --momentum 0.9 --weight-decay 0.01"],"metadata":{"id":"nqA9QkRtB9tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-large\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.05 --dropout 0.5 --momentum 0.9 --weight-decay 0.01"],"metadata":{"id":"joT22zzGB9kI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"REmxIHOCGDKK"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8218085106382979_mBERT.pt\""],"metadata":{"id":"qOxRjHk7GVtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-5_acc0-8271276595744681_xlm-roberta-base.pt\""],"metadata":{"id":"lT3IrpuQGWRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-5_acc0-776595744680851_xlm-roberta-large.pt\""],"metadata":{"id":"o1k7AxCAGW7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Multilingual dataset."],"metadata":{"id":"LpmvmNGFEqzh"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Multilingual language training data."],"metadata":{"id":"onuHr6rIsLz0"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"mBERT\""],"metadata":{"id":"msRA9JMFsLz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"xlm-roberta-base\""],"metadata":{"id":"dg5q8xnYsLz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"xlm-roberta-large\""],"metadata":{"id":"_uqGWNOosLz1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Multilingual language training data."],"metadata":{"id":"heCgLgY3sLz1"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum  0.85 --weight-decay 1e-05"],"metadata":{"id":"1tFFnYiYsLz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001"],"metadata":{"id":"qKJjtiWAsLz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-large\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum  0.85 --weight-decay 1e-05"],"metadata":{"id":"3OVKDmfFsLz1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"aYIuRvVKFlG6"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7918486171761281_mBERT.pt\""],"metadata":{"id":"Yqq4_bdiFlG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-4_acc0-8486171761280932_xlm-roberta-base.pt\""],"metadata":{"id":"Moc5pmr4FlG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8398835516739447_xlm-roberta-large.pt\""],"metadata":{"id":"aq5ZT-jmFlG6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset, using sentiment-level contrastive learning."],"metadata":{"id":"A6foZ_VmgPEa"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using English language training data."],"metadata":{"id":"Y25_hbigCinw"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"mBERT\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"sIcyH5nUCin2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"_eIAOtTtCin2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using English language training data."],"metadata":{"id":"TZd8S-4oCin2"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.5"],"metadata":{"id":"fe4Lht7MCin2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.4"],"metadata":{"id":"lTCva0gICin2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"SotXSIElgPEb"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8377659574468085_mBERT_CL_Sen.pt\""],"metadata":{"id":"Q3dYTsZYgPEb","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8537234042553191_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"Of72iesUgPEb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset, using representation-level contrastive learning."],"metadata":{"id":"03BHBw6qnTBJ"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using English language training data."],"metadata":{"id":"HEJ2frGjCoZI"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"mBERT\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"QeGQ9eWhCoZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"English\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"c_b1DXZHCoZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using English language training data."],"metadata":{"id":"fZUz8mGjCoZP"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001 --contrastive-learning \"Rep\" --beta 0.5"],"metadata":{"id":"WrVpYpnhCoZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"English\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001 --contrastive-learning \"Rep\" --beta 0.5"],"metadata":{"id":"B1V1eMRZCoZP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"AAmvt3aNnTBQ"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-4_acc0-8351063829787234_mBERT_CL_Rep.pt\""],"metadata":{"id":"kDJz-H1znTBR","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-4_acc0-848404255319149_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"zC6KMm6EnTBR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Multilingual dataset, using sentiment-level contrastive learning."],"metadata":{"id":"7aoIVjsMkQN1"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Multilingual language training data."],"metadata":{"id":"A3zbkHTspqrd"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"mBERT\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"VGHjZRRxrnEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"QFBueKDArqzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Multilingual language training data."],"metadata":{"id":"-tTaAMzcpwyG"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.4"],"metadata":{"id":"5GicVihbBHGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.4"],"metadata":{"id":"fkreOJZSD8nH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"zG7032ngkW4N"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"English\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7983988355167394_mBERT_CL_Sen.pt\""],"metadata":{"id":"xQy_iq-5kW4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Spanish\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8522561863173217_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"NooFehXQkW4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Multilingual dataset, using representation-level contrastive learning."],"metadata":{"id":"2MGpsbb4j2UO"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Multilingual language training data."],"metadata":{"id":"czoPGPXDprsi"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"mBERT\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"5qJhg6DCrYO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Multilingual\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"8LBry0EsrqzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Multilingual language training data."],"metadata":{"id":"S0Ou4lQspup9"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Rep\" --beta 0.3"],"metadata":{"id":"LFaBvWb14DMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Multilingual\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Rep\" --beta 0.5"],"metadata":{"id":"9aXgg_tt4DMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using English language test data."],"metadata":{"id":"WurX3U1Nj2UO"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Spanish\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7809315866084425_mBERT_CL_Rep.pt\""],"metadata":{"id":"4D_BiNf_j2UO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Spanish\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8427947598253275_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"fof_0nHtj2UO"},"execution_count":null,"outputs":[]}]}