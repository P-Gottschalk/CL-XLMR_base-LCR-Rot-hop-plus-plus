{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["###**Notebook Setup**"],"metadata":{"id":"A6IwkaSjh1Ul"}},{"cell_type":"markdown","source":["**  Mount Prep**"],"metadata":{"id":"IEAxUJ-S2dJB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZlNusdLTV0v"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"]},{"cell_type":"markdown","metadata":{"id":"vkx1Y9Qj5G_1"},"source":["**Package Installation:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wZfrg344lsI"},"outputs":[],"source":["! pip install matplotlib\n","! pip install torch\n","! pip install transformers\n","! pip install datasets\n","! pip install rdflib\n","! pip install tqdm\n","! pip install requests\n","! pip install hyperopt\n","! pip install scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"nu6jBbPL2q4F"},"source":["**GitHub Cloning:** 90-day access token is used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-qbm4XreAUf"},"outputs":[],"source":["! rm -r CL-XLMR_base-LCR-Rot-hop-plus-plus #Remove GitHub whilst in session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9Ovr3oPvWD7"},"outputs":[],"source":["!git clone https://github.com/SmartStevie02/CL-XLMR_base-LCR-Rot-hop-plus-plus.git"]},{"cell_type":"markdown","source":["### **XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset."],"metadata":{"id":"ZiFrbQ5zGo45"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"MTTqHNaDGo45"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"YCPnTJmqGo46"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"Fa3rtdBGGo46"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8218085106382979_mBERT.pt\""],"metadata":{"id":"vLSLaVm2Go46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-5_acc0-8271276595744681_xlm-roberta-base.pt\""],"metadata":{"id":"NHBoY8M0Go46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-5_acc0-776595744680851_xlm-roberta-large.pt\""],"metadata":{"id":"5dfiR_YWGo46"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **XLMR-LCR-Rot-hop-XX++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Dutch dataset."],"metadata":{"id":"Z6lXkq_w28id"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch language training data."],"metadata":{"id":"wUulWFqcAuaV"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"mBERT\""],"metadata":{"id":"EG6-Hk0iAfn4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"xlm-roberta-base\""],"metadata":{"id":"sFRBTGMnAhYA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"xlm-roberta-large\""],"metadata":{"id":"FzFpGEN6AhJs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Dutch language training data."],"metadata":{"id":"oSK97jQjBw1q"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.05 --dropout 0.5 --momentum 0.9 --weight-decay 0.01"],"metadata":{"id":"MzdHkxt0B88x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05"],"metadata":{"id":"nqA9QkRtB9tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-large\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001"],"metadata":{"id":"joT22zzGB9kI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"REmxIHOCGDKK"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-5_acc0-8093385214007782_mBERT.pt\""],"metadata":{"id":"qOxRjHk7GVtp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/data/models/2016_Dutch_LCR_hops2_dropout0-6000000000000001_acc0-8443579766536965_xlm-roberta-base.pt\""],"metadata":{"id":"lT3IrpuQGWRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-4_acc0-8054474708171206_xlm-roberta-large.pt\""],"metadata":{"id":"o1k7AxCAGW7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on a Multilingual dataset."],"metadata":{"id":"XFfc55XGC9vf"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"suHAbGzCC9vg"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"Chpj3fgpC9vg"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"R1dKeawMC9vg"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7918486171761281_mBERT.pt\""],"metadata":{"id":"LNIrTz2KC9vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-4_acc0-8486171761280932_xlm-roberta-base.pt\""],"metadata":{"id":"niyzSZL5C9vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8398835516739447_xlm-roberta-large.pt\""],"metadata":{"id":"j1xqaus2C9vh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **XLMR-LCR-Rot-hop-ACS_NL++:**\n","LCR-Rot-hop++ model, using various embedders, trained on a dataset which is created using Aspect-Code Switching."],"metadata":{"id":"epcQ2wdaDWac"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch language training data."],"metadata":{"id":"G1SUu32bDWac"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"mBERT\""],"metadata":{"id":"-90tWyvZDWac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"xlm-roberta-base\""],"metadata":{"id":"zMHVzvkqDWac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"xlm-roberta-large\""],"metadata":{"id":"8NzjdM-3DWac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using ACS Dutch language training data."],"metadata":{"id":"Lo7fFe2qIhml"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05"],"metadata":{"id":"_m_UegcyIhml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay  1e-05"],"metadata":{"id":"VT8Vm4rFIhml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-large\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay  1e-05"],"metadata":{"id":"iy3npKUQIhml"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"RpNw0XhHt0fA"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-8990578734858681_mBERT.pt\""],"metadata":{"id":"RUwIBCbpt0fB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-8835800807537012_xlm-roberta-base.pt\""],"metadata":{"id":"4wsZgHubt0fB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-large\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-8539703903095559_xlm-roberta-large.pt\""],"metadata":{"id":"Y-Ul4PF8t0fB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset, using sentiment-level contrastive learning."],"metadata":{"id":"A6foZ_VmgPEa"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"70n2L1MngPEb"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"XsWQs5LkgPEb"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"SotXSIElgPEb"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8377659574468085_mBERT_CL_Sen.pt\""],"metadata":{"id":"Q3dYTsZYgPEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-6000000000000001_acc0-8537234042553191_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"Of72iesUgPEb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-LCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the English dataset, using representation-level contrastive learning."],"metadata":{"id":"03BHBw6qnTBJ"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"A7JcQ9PrnTBQ"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using English training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"8AtJV_p2nTBQ"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"AAmvt3aNnTBQ"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-4_acc0-8351063829787234_mBERT_CL_Rep.pt\""],"metadata":{"id":"kDJz-H1znTBR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_English_LCR_hops2_dropout0-4_acc0-848404255319149_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"zC6KMm6EnTBR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-LCR-Rot-hop-XX++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Dutch dataset, using sentiment-level contrastive learning."],"metadata":{"id":"7aoIVjsMkQN1"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch language training data."],"metadata":{"id":"A3zbkHTspqrd"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"mBERT\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"VGHjZRRxrnEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"QFBueKDArqzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Dutch language training data."],"metadata":{"id":"-tTaAMzcpwyG"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001 --contrastive-learning \"Sen\" --beta 0.5"],"metadata":{"id":"5GicVihbBHGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.5"],"metadata":{"id":"fkreOJZSD8nH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"zG7032ngkW4N"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-4_acc0-8171206225680934_mBERT_CL_Sen.pt\""],"metadata":{"id":"xQy_iq-5kW4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-6000000000000001_acc0-8482490272373541_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"NooFehXQkW4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-LCR-Rot-hop-XX++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Dutch dataset, using representation-level contrastive learning."],"metadata":{"id":"2MGpsbb4j2UO"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch language training data."],"metadata":{"id":"czoPGPXDprsi"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"mBERT\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"5qJhg6DCrYO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"Dutch\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"8LBry0EsrqzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Dutch language training data."],"metadata":{"id":"S0Ou4lQspup9"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.06 --dropout 0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Rep\" --beta 0.4"],"metadata":{"id":"LFaBvWb14DMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"Dutch\" --hops 2 --learning 0.08 --dropout 0.4 --momentum 0.95 --weight-decay 0.0001 --contrastive-learning \"Rep\" --beta 0.1"],"metadata":{"id":"9aXgg_tt4DMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"WurX3U1Nj2UO"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-6000000000000001_acc0-8171206225680934_mBERT_CL_Rep.pt\""],"metadata":{"id":"4D_BiNf_j2UO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Dutch_LCR_hops2_dropout0-4_acc0-7976653696498055_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"fof_0nHtj2UO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Multilingual dataset, using sentiment-level contrastive learning."],"metadata":{"id":"SoELtyWLYbNi"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"n9f1RRfxYbNi"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"q7w8wuRKYbNi"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"H2-wFwu5YbNi"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7983988355167394_mBERT_CL_Sen.pt\""],"metadata":{"id":"rvoVUpojYbNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8522561863173217_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"7QgL6m_QYbNi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-MLCR-Rot-hop++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Multilingual dataset, using representation-level contrastive learning."],"metadata":{"id":"lsjDUE5MYbNi"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** since this optimisation is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"bw5fxwt6YbNj"}},{"cell_type":"markdown","source":["**Model Training:** since this training is carried out using Multilingual training data, this is carried out in a seperate file and used to test on all languages."],"metadata":{"id":"NKCjvGl4YbNj"}},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"Zt8SLXhGYbNj"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-7809315866084425_mBERT_CL_Rep.pt\""],"metadata":{"id":"sLcLrsGgYbNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_Multilingual_LCR_hops2_dropout0-6000000000000001_acc0-8427947598253275_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"fKnPcsu7YbNj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLS-XLMR-LCR-Rot-hop-ACS_NL++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Dutch ACS dataset, using sentiment-level contrastive learning."],"metadata":{"id":"Bg1c0vhbsBh4"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch ACS language training data."],"metadata":{"id":"E4dSu4ImsBh5"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"mBERT\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"6ngKn4nOsBh5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Sen\""],"metadata":{"collapsed":true,"id":"MP85QlzOsBh5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Dutch ACS language training data."],"metadata":{"id":"sLUbZI1KsBh5"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.5"],"metadata":{"id":"93-CDt2JsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Sen\" --beta 0.5"],"metadata":{"id":"SIGCWz3HsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"RMSDV-7ssBh6"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-923956931359354_mBERT_CL_Sen.pt\""],"metadata":{"id":"S_-nkiIgsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-9118438761776582_xlm-roberta-base_CL_Sen.pt\""],"metadata":{"id":"MoFti0QSsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **CLR-XLMR-LCR-Rot-hop-ACS_NL++:**\n","LCR-Rot-hop++ model, using various embedders, trained on the Dutch ACS dataset, using representation-level contrastive learning."],"metadata":{"id":"LxxGqWThsBh6"}},{"cell_type":"markdown","source":["**Hyperparameter Optimisation:** carry out hyperparameter optimisation of the various language models using Dutch ACS language training data."],"metadata":{"id":"iItQixUEsBh6"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"mBERT\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"_AEGjazGsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_hyperparam.py --year 2016 --phase \"Train\" --language \"XACSforDutch\" --model-type \"xlm-roberta-base\" --contrastive-learning \"Rep\""],"metadata":{"collapsed":true,"id":"-LpWhfWTsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Training:** trains the actual models using Dutch ACS language training data."],"metadata":{"id":"kzt9_XxpsBh6"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"mBERT\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Rep\" --beta 0.3"],"metadata":{"id":"1HSMQFbFsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_train.py --model-type \"xlm-roberta-base\" --year 2016 --phase \"Train\" --language \"XACSforDutch\" --hops 2 --learning 0.06 --dropout  0.6000000000000001 --momentum 0.85 --weight-decay 1e-05 --contrastive-learning \"Rep\" --beta 0.3"],"metadata":{"id":"tU36d98PsBh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Model Validation:** validates the models using Dutch language test data."],"metadata":{"id":"3dXi6NuVsBh7"}},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"mBERT\" --model \"/content/drive/MyDrive/Thesis_Data/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-8822341857335128_mBERT_CL_Rep.pt\""],"metadata":{"id":"M3iDndJ1sBh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! python /content/CL-XLMR_base-LCR-Rot-hop-plus-plus/main_validate.py --language \"Dutch\" --model-type \"xlm-roberta-base\" --model \"/content/drive/MyDrive/data/models/2016_XACSforDutch_LCR_hops2_dropout0-6000000000000001_acc0-8559892328398385_xlm-roberta-base_CL_Rep.pt\""],"metadata":{"id":"QalxczgysBh7"},"execution_count":null,"outputs":[]}]}  
